---
draw:
title: 显卡
date created: 2025-02-14
date modified: 2025-02-24
---

| 显卡型号 | 架构         | 显存          | 算力（FP16，约）| 定位与特点                              | 训练大模型"等级" |
|---------|--------------|---------------|-----------------------|----------------------------------------|------------------|
| RTX 3090| Ampere       | 24GB GDDR6X  | ~36 TFLOPS           | 民用游戏卡，入门级，显存小，通信弱       | 入门级           |
| V100    | Volta        | 16GB/32GB HBM2 | ~125 TFLOPS         | 老款专业卡，AI优化好但过时              | 中低级           |
| L20     | Hopper       | ~24GB HBM3   | 未公开（低于H20）| 特供版，性能被限制，中档选择            | 中级             |
| H20     | Hopper       | 96GB HBM3    | ~148 TFLOPS          | 特供版，显存大但算力受限                | 中级             |
| A800    | Ampere       | 40GB/80GB HBM2e | ~312 TFLOPS       | 特供版，中高端，性价比高                | 中高级           |
| H100    | Hopper       | 80GB HBM3    | ~1979 TFLOPS（稀疏）| 顶级专业卡，算力猛、显存快，价格昂贵    | 顶级             |

## 等级排序（训练大模型）

3090 < V100 < H20 ≈ L20 < A800 < A100 < H100

## 说明

- **3090**: 适合小模型或推理，便宜但不专业。
- **V100**: 曾经的王者，现在稍显落后。
- **H20/L20**: 中档特供，性能被砍，显存和算力中等。
- **A800**: 中高端，能应付大部分任务。
- **H100**: 当前最强，专为大模型设计，土豪专属。

首先，这些显卡（H20、L20、3090、V100、A800、H100）都是NVIDIA的产物，专门用来干算力活儿，尤其是训练大模型这种需要"烧脑"的任务。它们的性能差距主要体现在计算能力、显存大小和带宽上，咱们从低到高排个序，给你捋捋清楚。

---

3090：入门级"民用战士"

RTX 3090是个"游戏卡"出身，但因为有24GB显存和不错的算力，小白或者预算有限的人可能会拿它试试水。不过，训练大模型它就有点吃力了。想象一下，它像个跑步爱好者，能跑5公里，但你要它跑马拉松，腿就软了。它适合小模型或者推理（跑已经训练好的模型），但大模型训练需要多卡联动，3090的通信能力弱，显存也不够大，所以在专业领域它算是个"新手村装备"。

---

V100：老将，但不落伍

V100是NVIDIA几年前的"计算卡"王者，属于Volta架构，有16GB或32GB显存版本。它的算力比3090强，尤其是专门为AI设计的Tensor Core很给力，当时训练大模型挺常见。不过现在看，它有点像个退役的老兵，虽然经验丰富，但体力（算力和显存）跟不上新一代的需求了。比3090高一级，但已经被更强的卡甩在后面。

---

H20和L20：特供"缩水版"

H20和L20是NVIDIA为特定市场（比如中国）推出的"特供版"，基于Hopper架构，本来想接替H100的班，但性能被砍了不少。H20有96GB显存，算力大概148 TFLOPS（FP16），L20显存少点（24GB左右），算力也更低。这俩就像是H100的"弟弟"，有点像买了个旗舰手机的青春版，外观差不多，但跑起来差远了。比3090和V100强，但跟后面几款比，还是"中档选手"。

---

A800：中高端"替代品"

A800是A100的"特供版"，Ampere架构，显存有40GB或80GB版本，算力大概312 TFLOPS（FP16）。它是为了替代A100在某些市场用的，性能比H20、L20高不少，比V100也强，但跟顶级的H100比还有差距。你可以把它想象成一个"副队长"，干活靠谱，但不是最牛的那个。

---

H100：现役"王者"

H100是现在NVIDIA的顶级货，Hopper架构，80GB HBM3显存，算力直接飙到1979 TFLOPS（FP16，稀疏计算）。它就像个超人，显存快、算力猛、通信强，专门为大模型训练生的。无论是跑超大参数模型还是多卡并行，它都是"天花板级别"。价格也贵得离谱，普通人只能看看。跟前面那些比，它就是"土豪专属神器"。

---

如果你是大模型小白，想练手，3090够用了，便宜还能搞到；如果预算多点，V100或H20/L20可以试试，性价比还行；要是公司干活或者追求极致，A800和H100是正经选择，尤其是H100，简直是"大模型训练的兰博基尼"。不过这些卡价格差很大，得看你兜里有多少银子啦！有什么不懂的再问我哈！

"八卡H100"是指一台机器里装了八块NVIDIA H100显卡。简单来说，就是一个高性能计算系统，用了八个目前最顶级的GPU（图形处理器），专门用来干那种特别费算力的大活儿，比如训练超大的AI模型（像ChatGPT那种）、跑科学模拟或者处理海量数据。
