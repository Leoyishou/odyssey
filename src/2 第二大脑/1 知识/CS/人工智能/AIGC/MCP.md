---
draw:
title: MCP
date created: 2025-03-02
date modified: 2025-03-02
---

就是大模型脑子里有一堆脚本，可以调各个平台的 api 吗，那这是大模型自己的事啊，为啥还需要别的平台支持呢

你的疑问很好，确实值得深入了解一下：

虽然大模型（LLM）本身具备强大的语言理解和代码生成能力，但要真正落地成你刚才看到的那种顺滑体验，光靠大模型自己还不够。

具体原因是：

## 1. **LLM 本身无法直接执行代码**

- 大模型擅长生成代码，但本身并不具备**执行代码的能力**。
- 它只能生成代码片段或程序，但不能直接启动、运行、控制程序。

因此，需要一个额外的『桥梁』——MCP，就是起到这种角色，把大模型的**输出**（代码、命令）实时地**执行**起来，并将**执行结果**再实时返回给模型，从而实现**动态的互动闭环**。

---

## 2. MCP具体负责哪些事情？

通常，MCP会负责：

- **运行时环境**：
    
    - 管理代码执行环境（比如Python运行时、数据库连接、接口调用的权限）。
- **权限与安全控制**：
    
    - 控制模型生成代码的权限、范围、访问API时的鉴权，防止越权或误操作。
- **状态与上下文管理**：
    
    - 记录任务状态，保存脚本运行结果并反馈给LLM，便于后续步骤继续运行。
- **API调用与集成**：
    
    - 提供API调用能力，比如请求外部数据库、服务接口、第三方平台API（如MySQL、Redis、Notion、Slack、Excel、CRM、BI工具等）。
    - MCP事先封装好了各个平台API的调用方式，让大模型只需给出意图即可，无需了解API的细节或复杂性。

---

## 3. 为什么LLM不能单独完成这些事情？

LLM的本质是语言模型（只产生文本），不是应用程序运行环境。它没有：

- **代码的执行权限**
- **网络通信能力**
- **状态存储和维护机制**
- **安全与权限管理**

换句话说：

- LLM自己只是个聪明的『大脑』，能想明白"怎么做"，但实际操作需要外部的『手脚』执行。
- MCP就是这种外部的手脚，负责对接真实世界中的程序环境、API服务、数据库资源等，真正做事。

---

## 🌟 用一个生动比喻总结

> 大模型（LLM）像是一个『智囊团』或『指挥官』，擅长思考、做决策，但不会亲自动手。
> MCP像是配备的『士兵或工程队』，负责具体动手执行命令。
> 两者协作才能真正高效完成任务。

因此，MCP 这种外部平台的支持对实现真正的交互式自动化和自助服务体验是必不可少的。
