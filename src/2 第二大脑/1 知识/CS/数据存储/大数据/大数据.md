---
draw:
title: 大数据
date created: 2024-11-23
date modified: 2025-02-24
---
- Hadoop 是基础，提供分布式存储（HDFS）和计算能力（MapReduce）。
    
- MapReduce 是 Hadoop 的一种计算方式，像个老工人，干活靠谱但效率不高。
    
- Hive 站在 Hadoop 肩膀上，帮你把 SQL 翻译成 MapReduce 任务，适合查大数据。
    
- Spark 是新世代工具，速度快、功能多，能用 HDFS 存数据，但计算上比 MapReduce 高级。
    
- Flink 也是新工具，特别擅长实时流处理，也能跟 HDFS 搭档。
    

它们就像一个团队：Hadoop 是仓库管理员，MapReduce 是老员工，Hive 是文员，Spark 是全能选手，Flink 是实时专家。大家可以一起干活，也可以各干各的。

数据存储在 **HDFS**，计算引擎可以是 **MapReduce、Tez、[[Spark]]**。

- **小数据、高并发** → MySQL / PostgreSQL / Redis
- **大数据、批处理** → HDFS + Hive / Spark
- **云存储、大规模数据分析** → AWS S3 / 阿里 OSS + Spark

## **1. 最核心的区别：数据量和计算方式**

| **普通数据库（MySQL / PostgreSQL）** | **大数据（Hadoop / Hive / Spark）** |                       |
| ----------------------------- | ------------------------------ | --------------------- |
| **数据规模**                      | GB 级别（最多几 TB）| TB 甚至 PB 级（海量数据）|
| **计算方式**                      | 单机计算为主                         | 分布式计算（多台机器一起算）|
| **数据存储**                      | 硬盘 / 内存（B+ 树索引）| [[HDFS]] / 对象存储（文件系统）|
| **查询速度**                      | 适合秒级查询                         | 适合大规模批量计算             |
| **事务支持**                      | 强事务 ACID，适合高并发                 | 一般没有事务，适合批处理          |

**通俗理解**：

- **MySQL/PostgreSQL = 小超市** → 适合存**几十万、几百万条**数据，数据量太大就吃不消了。
- **大数据（Hive/Spark）= 物流仓库** → 适合存**几十亿、几千亿条数据**，查询时需要**批量计算、分布式处理**。

---

## **2. 适用场景对比**

**🟢 MySQL / PostgreSQL（适合小数据、高并发）** 适合 **小型、中型数据业务**，比如：

- 业务系统：**用户管理、订单系统、支付系统**
- 实时查询：**Web API，秒级响应**
- 交易系统：**银行、购物网站（需要事务和一致性）**
- **高并发读写**（例如秒杀系统，Redis+MySQL 组合）

**🟢 大数据（Hadoop / Hive / Spark，适合海量数据分析）** 适合 **超大数据量、需要批量计算的业务**，比如：

- 日志分析：**用户访问日志、点击流分析**
- 数据仓库：**存储并分析多年业务数据**
- 推荐系统：**基于用户行为分析个性化推荐**
- 机器学习：**在超大数据集上做训练**
- 数据 ETL（Extract, Transform, Load）：**批量数据清洗、转换**
- BI 报表：**企业级数据分析（如 Hive+Spark 生成大屏数据报表）**

---

## **3. 举个开发中的例子**

**场景：电商网站** 你开发了一个电商网站，数据库选型如下：

|业务|用什么数据库？|为什么？|
|---|---|---|
|**订单系统**|**MySQL / PostgreSQL**|需要支持事务，保证订单一致性|
|**用户登录、权限管理**|**MySQL / PostgreSQL**|需要快速响应，数据量不会太大|
|**秒杀活动**|**Redis + MySQL**|高并发读写，Redis 缓存热点数据|
|**日志存储（用户点击、访问）**|**HDFS / Hive**|PB 级别数据，存储到 Hadoop 里做分析|
|**商品推荐**|**Hive + Spark**|需要基于用户行为大规模计算推荐结果|
|**大屏数据报表**|**Hive + Spark + Presto**|需要从海量数据中统计销售情况|

### **如果用错数据库会怎么样？**

❌ **把订单系统放到 Hive？**  
→ **订单查询会慢到爆炸**，因为 Hive 适合批处理，查询不是秒级响应。

❌ **把点击日志全存到 MySQL？**  
→ **数据库会被写爆**，大数据量会导致 MySQL 性能下降，Hive 更适合批量存储。

---

## **4. 如何选择合适的数据库？**

|你的需求|推荐数据库|
|---|---|
|需要高并发、小数据、事务支持（银行、订单）|**MySQL / PostgreSQL**|
|需要批量计算、大数据存储（日志分析、BI 报表）|**Hive / Spark / HDFS**|
|需要低延迟查询（搜索、缓存）|**Redis / Elasticsearch**|
|需要 NoSQL（灵活结构存储）|**MongoDB / HBase**|

---

## **5. 总结**

- **MySQL/PostgreSQL**：适合**小数据、高并发、事务性操作**（例如订单管理、用户管理、秒杀等）。
- **大数据（Hive/Spark/HDFS）**：适合**超大数据量、批量分析**（例如日志分析、机器学习、数据仓库）。
- **Redis / Elasticsearch**：适合**缓存、搜索、实时查询**。

---

你是做**后端开发**的，在实际业务中，通常会**结合多种数据库**来优化性能：

- 订单系统 → **MySQL**
- 缓存热点数据 → **Redis**
- 大数据分析 → **Hive / Spark**
- 搜索推荐 → **Elasticsearch**
- 用户行为分析 → **Hadoop / Presto**

这样既能保证**高并发小数据的快速查询**，又能满足**大数据的存储和计算**。你可以根据**业务需求**选择合适的数据库架构！💡

如果你有具体业务场景想讨论，我可以给你更详细的数据库选型建议！🚀

是的，流式计算属于大数据处理领域。让我展开解释一下大数据的技术栈：

**大数据技术栈分层**：

## **数据收集/采集**

- Flume, Kafka, Logstash
- 负责收集各种来源的数据流

## **数据存储**

- HDFS（分布式文件系统）
- HBase, Cassandra（列式存储）
- MongoDB（文档型数据库）

## **数据处理**

- **批处理**
  - [[Hadoop]]
  - [[MapReduce]]
  - Spark 批处理
  
- **[[流式处理]]**
  - [[Flink]]
  - [[Spark]] Streaming
  - Storm
  - Samza

## **资源调度**

- YARN
- Kubernetes
- Mesos

## **查询分析**

- [[Hive]]（数据仓库）
- Presto（交互式查询）
- Impala

## **可视化/应用层**

- Tableau
- Superset
- 自定义应用
