---
comment_id: f0096829
date created: 2025-07-04
date modified: 2025-07-04
draw: null
title: FlashAttention
---
FlashAttention FlashAttention 能够加快注意力机制的运算速度，同时减少对内存的使用。如果您想使用 FlashAttention，请在启动训练时在训练配置文件中添加以下参数：
