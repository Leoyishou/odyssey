---
date created: 2024-09-22
date modified: 2025-07-10
uid: b905b5bc-adfd-4fde-993c-d7ca81d2fa34
---
> _**反向传播算法 = 多元微积分 + 链式法则** (在多层结构上的系统应用)。这就是它的数学来源与本质所在  
> 把神经网络想象成一个 n 个权重参数和 k 个bias 参数的超大函数，反向传播使得我们每次只关注前一层，也就是只关注 n 和 k 中的一部分即可

## 例子

![image.png|1000](https://imagehosting4picgo.oss-cn-beijing.aliyuncs.com/imagehosting/fix-dir%2Fpicgo%2Fpicgo-clipboard-images%2F2025%2F01%2F26%2F17-11-08-23b92ea8f94d137be070996366dea9a6-202501261711777-7e48d7.png)

### 1. 输入层到隐藏层的计算

$z^{(1)} = W^{(1)}x + b^{(1)}$  
$a^{(1)} = \sigma(z^{(1)})$

```Java
第一步: 计算加权和 z¹ = W¹x + b¹

[0.2  -0.5  0.1]     [2]     [0.3]     [0.2(2) + (-0.5)(3) + 0.1(-1) + 0.3] 
[-0.3  0.4  0.2]  ×  [3]  +  [-0.1]  = [-0.3(2) + 0.4(3) + 0.2(-1) - 0.1]
                     [-1]

详细计算:
z₁ = 0.2(2) + (-0.5)(3) + 0.1(-1) + 0.3
   = 0.4 - 1.5 - 0.1 + 0.3 
   = -0.9

z₂ = -0.3(2) + 0.4(3) + 0.2(-1) - 0.1
   = -0.6 + 1.2 - 0.2 - 0.1
   = 0.3

第二步: 应用Sigmoid激活函数 a¹ = σ(z¹)
a₁ = σ(-0.9) = 1/(1 + e⁰·⁹) ≈ 0.29
a₂ = σ(0.3) = 1/(1 + e⁻⁰·³) ≈ 0.57
```

### 2. 隐藏层到输出层的计算

$z^{(2)} = W^{(2)}a^{(1)} + b^{(2)}$  
$a^{(2)} = \sigma(z^{(2)})$

```Java
第一步: 计算加权和 z² = W²a¹ + b²

[0.5  0.2] × [0.29]  + [0.1] = [0.5(0.29) + 0.2(0.57) + 0.1]
             [0.57]

详细计算:
z² = 0.5(0.29) + 0.2(0.57) + 0.1
   = 0.145 + 0.114 + 0.1
   = 0.359

第二步: 应用Sigmoid激活函数 a² = σ(z²)
输出 = σ(0.359) = 1/(1 + e⁻⁰·³⁵⁹) ≈ 0.589
```

### 3. 损失函数

对于使用均方误差(MSE)作为损失函数  
$C_0 = (a^{(L)} - y)^2$

- $a^{(L)}$ 是神经网络的输出值（预测值），在我们前面的例子中是 0.589
- $y$ 是我们希望网络输出的正确答案，也就是训练数据中的目标值（比如如果这是一个二分类问题，y 可能是 0 或 1）

### 4. 链式法则 & 反向传播

![image.png|1000](https://imagehosting4picgo.oss-cn-beijing.aliyuncs.com/imagehosting/fix-dir%2Fpicgo%2Fpicgo-clipboard-images%2F2025%2F01%2F26%2F16-50-06-45c7ca7e2b4d7d5b0fa4b7bd39c27beb-202501261650495-d0f96e.png)

$\frac{\partial C_0}{\partial w^{(L)}} = \frac{\partial z^{(L)}}{\partial w^{(L)}} \frac{\partial a^{(L)}}{\partial z^{(L)}} \frac{\partial C_0}{\partial a^{(L)}}$

其中:

1. $\frac{\partial C_0}{\partial a^{(L)}} = 2(a^{(L)} - y)$
2. $\frac{\partial a^{(L)}}{\partial z^{(L)}} = \sigma'(z^{(L)})$
3. $\frac{\partial z^{(L)}}{\partial w^{(L)}} = a^{(L-1)}$

#### 输出层参数梯度计算

对于权重 $W^{(2)}=[0.5,0.2]$ 的梯度:

1. $\frac{\partial C_0}{\partial a^{(2)}} = 2(a^{(2)} - y) = 2(0.589 - 1) = -0.822$
2. $\frac{\partial a^{(2)}}{\partial z^{(2)}} = \sigma'(z^{(2)}) = a^{(2)}(1-a^{(2)}) = 0.589(1-0.589) = 0.242$
3. $\frac{\partial z^{(2)}}{\partial W^{(2)}} = a^{(1)} =[0.289, 0.574]$，因为$z^{(2)} = W^{(2)}a^{(1)} + b^{(2)}$

$W^{(2)} =[0.5, 0.2]$  
所以对于 $W_1^{(2)}$: 也就是 0.5  
$\frac{\partial C_0}{\partial W_1^{(2)}} = (-0.822) \times 0.242 \times 0.289 \approx -0.0287$

对于 $W_2^{(2)}$: 也就是 0.2  
$\frac{\partial C_0}{\partial W_2^{(2)}} = (-0.822) \times 0.242 \times 0.574 \approx -0.0572$

这样的表示更清晰地展示了每个导数项的来源和计算过程。每个导数项都有其明确的物理含义:

- $\frac{\partial C_0}{\partial a^{(L)}}$ 表示损失相对于输出的敏感度
- $\frac{\partial a^{(L)}}{\partial z^{(L)}}$ 表示激活函数的导数
- $\frac{\partial z^{(L)}}{\partial w^{(L)}}$ 表示上一层的激活值

这种链式表示方法使得我们能更好地理解梯度是如何从输出层一步步反向传播的。

来推导对偏置 $b^{(2)}$ 的偏导数。

我们仍然使用链式法则：

$\frac{\partial C_0}{\partial b^{(2)}} = \frac{\partial z^{(2)}}{\partial b^{(2)}} \frac{\partial a^{(2)}}{\partial z^{(2)}} \frac{\partial C_0}{\partial a^{(2)}}$

其中：

1. $\frac{\partial C_0}{\partial a^{(2)}} = 2(a^{(2)} - y) = -0.822$ (与之前相同)
2. $\frac{\partial a^{(2)}}{\partial z^{(2)}} = \sigma'(z^{(2)}) = 0.242$ (与之前相同)
3. $\frac{\partial z^{(2)}}{\partial b^{(2)}} = 1$ (因为 $z^{(2)} = W^{(2)}a^{(1)} + b^{(2)}$，对 $b^{(2)}$ 求导就是 1)

所以：

$\frac{\partial C_0}{\partial b^{(2)}} = (-0.822) \times 0.242 \times 1 \approx -0.199$

### 5. 参数更新（优化算法）

#### SGD (Stochastic Gradient Descent，随机梯度下降)

假设学习率 η = 0.1，参数更新公式为：

```Java
W = W - η * ∂C/∂W
b = b - η * ∂C/∂b
```

对于输出层的参数更新：

```Java
W₁² = 0.5 - 0.1 * (-0.0287) = 0.50287
W₂² = 0.2 - 0.1 * (-0.0572) = 0.20572
b² = 0.1 - 0.1 * (-0.199) = 0.1199
```

是的,参数更新后需要进行前向传播计算新的输出值,然后计算新的损失值,这就是一次完整的训练迭代。让我们用更新后的参数计算一次:

#### Adam

Adam 结合了 RMSprop 和 Momentum，需要维护两个动量变量 m (一阶动量) 和 v (二阶动量)。

假设：

- β₁ = 0.9 (一阶动量衰减率)
- β₂ = 0.999 (二阶动量衰减率)
- eps = 1e-8 (数值稳定性常数)
- learning_rate = 0.1

对于输出层的参数 W₁², W₂², b² 的梯度：

```python
# 之前计算的梯度值
dW₁² = -0.0287
dW₂² = -0.0572
db² = -0.199

# 初始化动量变量（假设是第一次更新）
m_W₁² = 0
m_W₂² = 0
m_b² = 0

v_W₁² = 0
v_W₂² = 0
v_b² = 0

# 更新一阶动量 m
m_W₁² = β₁ * m_W₁² + (1-β₁) * dW₁²
m_W₂² = β₁ * m_W₂² + (1-β₁) * dW₂²
m_b² = β₁ * m_b² + (1-β₁) * db²

# 计算结果
m_W₁² = 0.9 * 0 + 0.1 * (-0.0287) = -0.00287
m_W₂² = 0.9 * 0 + 0.1 * (-0.0572) = -0.00572
m_b² = 0.9 * 0 + 0.1 * (-0.199) = -0.0199

# 更新二阶动量 v
v_W₁² = β₂ * v_W₁² + (1-β₂) * (dW₁²)²
v_W₂² = β₂ * v_W₂² + (1-β₂) * (dW₂²)²
v_b² = β₂ * v_b² + (1-β₂) * (db²)²

# 计算结果
v_W₁² = 0.999 * 0 + 0.001 * (-0.0287)² = 8.24e-7
v_W₂² = 0.999 * 0 + 0.001 * (-0.0572)² = 3.27e-6
v_b² = 0.999 * 0 + 0.001 * (-0.199)² = 3.96e-5

# 参数更新
W₁² = W₁² - learning_rate * m_W₁² / (sqrt(v_W₁²) + eps)
W₂² = W₂² - learning_rate * m_W₂² / (sqrt(v_W₂²) + eps)
b² = b² - learning_rate * m_b² / (sqrt(v_b²) + eps)

# 计算结果
W₁² = 0.5 - 0.1 * (-0.00287) / (sqrt(8.24e-7) + 1e-8) ≈ 0.5003
W₂² = 0.2 - 0.1 * (-0.00572) / (sqrt(3.27e-6) + 1e-8) ≈ 0.2006
b² = 0.1 - 0.1 * (-0.0199) / (sqrt(3.96e-5) + 1e-8) ≈ 0.1021
```

与之前的 SGD 更新结果对比：

```Java
SGD:
W₁² = 0.50287
W₂² = 0.20572
b² = 0.1199

Adam:
W₁² = 0.5003
W₂² = 0.2006
b² = 0.1021
```

主要区别：

1. Adam 的更新幅度更小，更稳定。这是因为：
   - 一阶动量帮助累积历史梯度信息
   - 二阶动量自适应调整每个参数的学习率

2. Adam 维护了额外的状态（m 和 v），这些状态会影响后续的更新：
   - m 帮助保持梯度方向的连续性
   - v 帮助自适应调整学习率

3. Adam 通常能更快地收敛，因为它：
   - 可以处理稀疏梯度
   - 自动调整学习率
   - 结合了动量的优势

这就是为什么 Adam 在实践中经常是首选的优化器，它结合了 RMSprop 的自适应学习率和 Momentum 的动量特性。

### 6. 使用更新后的参数进行前向传播

隐藏层计算(这部分参数未更新,结果不变)

```Java
z₁ = -0.9, a₁ = 0.289
z₂ = 0.3,  a₂ = 0.574
```

输出层计算(使用更新后的参数)

```Java
z² = W₁²a₁ + W₂²a₂ + b²
   = 0.50287(0.289) + 0.20572(0.574) + 0.1199
   = 0.145329 + 0.118083 + 0.1199
   = 0.383312

a² = σ(0.383312) ≈ 0.595
```

计算新的损失值

```Java
对于目标值 y = 1:
C_new = (a² - y)² 
      = (0.595 - 1)² 
      = 0.164025
```

对比原来的损失值:

```Java
C_old = (0.589 - 1)² = 0.168921
```

可以看到损失值从 0.168921 降到了 0.164025,说明这次参数更新是有效的。这就是一次完整的训练迭代。

训练过程会不断重复这个循环:

1. 前向传播
2. 计算损失
3. 反向传播计算梯度
4. 更新参数
5. 重复以上步骤

直到满足停止条件,比如:

- 达到预设的迭代次数
- 损失值小于某个阈值
- 损失值的变化小于某个阈值(收敛)

每次迭代损失值都会略有下降,这样经过多次迭代后,网络的输出会越来越接近目标值。

```mermaid
flowchart TD
    A[开始训练] --> B[前向传播]
    B --> C[计算损失]
    C --> D[反向传播计算梯度]
    D --> E[更新参数]
    E --> F{检查停止条件}
    
    F -->|否| G{判断停止条件}
    G -->|达到最大迭代次数| H[结束训练]
    G -->|损失值小于阈值| H
    G -->|损失值变化小于阈值| H
    G -->|继续训练| B
    
    F -->|是| H
    
    style A fill:#d0f4de
    style H fill:#f4d0d0
    style F fill:#f4e5d0
    style G fill:#f4e5d0
```
