---
aliases: [卷积神经网络]
draw: 
title: CNN
date created: 2024-09-22
date modified: 2025-03-23
---

做[[卷积 convolution]]的目的是为了用一种数学的方法把各种猫猫图片中的共性提取出来。卷机核是想要的特征，有几个卷机核就有几个简化特征图，滑动窗口的方式遍历一遍图像，就知道哪个区域这种特征的满足程度

1. 输入文本转词向量矩阵:

```Java
句子: "I love deep learning"

词向量矩阵:
I     [0.2, 0.5, 0.1]
love  [0.8, 0.2, 0.7]     
deep  [0.4, 0.9, 0.3]     
learning [0.6, 0.3, 0.8]  
```

2. 卷积窗口滑动 (以 3-gram 为例):

```Java
Step 1:
[I     [0.2, 0.5, 0.1]] ─┐
[love  [0.8, 0.2, 0.7]]  ├─> Conv -> [0.6]
[deep  [0.4, 0.9, 0.3]] ─┘

Step 2:
[love  [0.8, 0.2, 0.7]] ─┐
[deep  [0.4, 0.9, 0.3]]  ├─> Conv -> [0.8]
[learning [0.6, 0.3, 0.8]] ─┘
```

3. 得到特征图:

```Java
Feature Map:
[0.6]
[0.8]
```

4. 最大池化:

```Java
Max Pooling:
[0.6, 0.8] -> [0.8]
```

- **为什么用 Max Pooling？**
    - 当激活函数是 ReLU 时，负值会被截断到 0，最小值经常无法有效代表特征。
    - max pooling 可以挑选最显著、最强的特征值。
- **k-max Pooling**：是更一般的操作，一次可以取出最大的 kkk 个值，而不止取 1 个最大值。例如把卷积输出的前 k 大值组成一个新的向量。

1. 完整的 CNN 架构:

```Java
Input         Conv       Pool     Output
              ┌─────┐      
[I]──────────►│     │      
[love]───────►│     │──►[0.6]─┐     
[deep]───────►│     │    [0.8]┼──►[0.8]
[learning]───►│     │         │     
              └─────┘         
```

这个过程的关键点:

```Java
* -----> 方向表示数据流动
│
├─ 表示数据合并或分支
└─ 表示处理单元的边界
```

每个卷积核就像一个"扫描仪":

```Java
     ╔═══════╗
Text │Scanner│ -> Features
     ╚═══════╝
     sliding ->
```

不同大小的卷积核可以同时工作:

```Java
2-gram: [--]
3-gram: [---]  并行扫描
4-gram: [----]
```

这就是为什么 CNN 能高效地处理文本 - 它可以:

1. 同时检测多种长度的词组模式
2. 并行处理所有滑动窗口
3. 自动提取最重要的特征
