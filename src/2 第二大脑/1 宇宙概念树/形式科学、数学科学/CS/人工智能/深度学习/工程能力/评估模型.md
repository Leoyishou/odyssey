---
date created: 2025-03-25
date modified: 2025-07-10
uid: 0fe9997b-2556-4daf-8edc-0d78f56bc04e
---
## ğŸ“Œ ä¸€ã€è¯„ä¼°ï¼ˆEvaluationï¼‰æ¨¡å‹æ€§èƒ½

åœ¨Open-R1é¡¹ç›®ä¸­ï¼Œä½¿ç”¨äº†`lighteval`å·¥å…·æ¥è¿›è¡Œæ¨¡å‹è¯„ä¼°ï¼Œä½ å¯ä»¥ç›´æ¥ä½¿ç”¨é¡¹ç›®æä¾›çš„è„šæœ¬ã€‚

**ä¾‹å¦‚ï¼Œä»¥AIME2024æ•°æ®é›†ä¸ºä¾‹ï¼š**

åœ¨ç»ˆç«¯æ‰§è¡Œï¼ˆä»¥ä¸‹æ˜¯é€‚ç”¨äºå•GPUçš„ç®€å•ç¤ºä¾‹ï¼‰ï¼š

```bash
MODEL=ä½ çš„æ¨¡å‹ç›®å½•è·¯å¾„ï¼ˆä¾‹å¦‚ï¼šdata/Qwen2.5-1.5B-Open-R1-Distillï¼‰
MODEL_ARGS="pretrained=$MODEL,dtype=bfloat16,max_model_length=32768,gpu_memory_utilization=0.8,generation_parameters={max_new_tokens:32768,temperature:0.6,top_p:0.95}"
OUTPUT_DIR=./data/evals/your_model_eval_results

TASK=aime24
lighteval vllm $MODEL_ARGS "custom|$TASK|0|0" \
    --custom-tasks src/open_r1/evaluate.py \
    --use-chat-template \
    --output-dir $OUTPUT_DIR
```

æ‰§è¡Œå®Œæˆåä¼šåœ¨`$OUTPUT_DIR`ä¸­ç”Ÿæˆè¯„ä¼°ç»“æœï¼Œå¯ç›´æ¥æŸ¥çœ‹ã€‚

ç±»ä¼¼çš„æ–¹å¼ï¼Œä½ ä¹Ÿå¯ä»¥è¯„ä¼°ï¼š

- `math_500`ï¼šæ•°å­¦æ¨ç†ä»»åŠ¡
- `gpqa:diamond`ï¼šå¸¸è¯†æ¨ç†ä»»åŠ¡
- `lcb:codegeneration`ï¼šä»£ç ç”Ÿæˆä»»åŠ¡

åªéœ€å°†ä¸Šé¢çš„`TASK`å˜é‡æ”¹æˆä½ æƒ³è¯„ä¼°çš„ä»»åŠ¡åç§°å³å¯ã€‚

---

## ğŸ“Œ äºŒã€äººå·¥è¯„ä¼°æ¨¡å‹æ¨ç†èƒ½åŠ›

ä½ ä¹Ÿå¯ä»¥ç›´æ¥è°ƒç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œäººå·¥éªŒè¯ä¸€äº›é—®é¢˜ï¼š

**ä½¿ç”¨ Hugging Face transformers åº“è¿›è¡Œæ¨ç†ï¼š**

### CPU æ¨ç†

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

model_path = "data/Qwen2.5-1.5B-Open-R1-Distill"

tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)

# CPUæ¨¡å¼ä¸‹ç¦ç”¨æ‰€æœ‰GPUç‰¹æ®Šä¼˜åŒ–ï¼Œç›´æ¥ç”¨float32ç¨³å®šè¿è¡Œ
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map='cpu',
    trust_remote_code=True,
    torch_dtype=torch.float32,
    use_sliding_window=False
)

prompt = "Solve the following math problem step-by-step: What is 13 multiplied by 15?"

inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs, max_new_tokens=256, do_sample=True, temperature=0.7)

response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)


```

### GPU æ¨ç†

```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

model_path = "data/Qwen2.5-1.5B-Open-R1-Distill"
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)

model = AutoModelForCausalLM.from_pretrained(
    model_path,
    device_map='auto',
    trust_remote_code=True,
    torch_dtype=torch.float16,
    attn_implementation='flash_attention_2',
    use_sliding_window=False
)

prompt = "Solve the following math problem step-by-step: What is 13 multiplied by 15?"

inputs = tokenizer(prompt, return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=256, do_sample=True, temperature=0.7)

response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(response)

```

é€šè¿‡è¿™ç§æ–¹å¼ï¼Œä½ å¯ä»¥å¿«é€Ÿæ„Ÿå—ä¸€ä¸‹æ¨¡å‹çš„å®é™…æ¨ç†è¡¨ç°ï¼Œåˆ¤æ–­å…¶æ¨ç†èƒ½åŠ›æ˜¯å¦ç¬¦åˆä½ çš„é¢„æœŸã€‚

---

## ğŸ“Œ ä¸‰ã€æ¨¡å‹æ¨ç†æ•ˆæœå®šé‡åˆ†æï¼ˆæŒ‡æ ‡å¯¹æ¯”ï¼‰

ä½ å¯ä»¥åŒæ—¶è¯„ä¼°è®­ç»ƒå‰åçš„æ¨¡å‹æŒ‡æ ‡å¯¹æ¯”ï¼Œä¾‹å¦‚Lossã€Accuracyã€Pass Rateï¼ˆé€šè¿‡ç‡ï¼‰ç­‰ï¼š

|æ–¹æ³•|æŒ‡æ ‡|æ¨èçš„benchmarkæ•°æ®é›†|
|---|---|---|
|æ•°å­¦æ¨ç†|Pass Rateï¼ˆé€šè¿‡ç‡ï¼‰|`math_500`, `aime24`|
|ä»£ç ç”Ÿæˆ|Pass Rate|`lcb:codegeneration`ï¼ˆLiveCodeBenchï¼‰|
|å¸¸è¯†æ¨ç†|Accuracy|`gpqa:diamond`|

åœ¨æ¨¡å‹è®­ç»ƒå‰ååˆ†åˆ«è¯„ä¼°è¿™äº›benchmarkï¼Œç„¶åæ¯”è¾ƒä¸¤ä¸ªç»“æœçš„å·®è·ï¼Œå¯ä»¥æ¸…æ™°äº†è§£æ¨¡å‹çš„æå‡ã€‚

---

## ğŸ“Œ å››ã€æ¨¡å‹éƒ¨ç½²åå®é™…åœºæ™¯æµ‹è¯•

- è‹¥ä½ çš„æ¨¡å‹æœ‰ç‰¹å®šçš„ä¸‹æ¸¸ä»»åŠ¡ï¼ˆä¾‹å¦‚å¯¹è¯æœºå™¨äººã€æ•°å­¦æ±‚è§£ç­‰ï¼‰ï¼Œå¯å°†æ¨¡å‹é›†æˆåˆ°å®é™…åœºæ™¯ä¸­ï¼Œè¿›è¡Œæµ‹è¯•ï¼Œä»¥è¯„ä¼°çœŸå®çš„åº”ç”¨æ€§èƒ½ã€‚

---

## ğŸŒŸ æ¨èçš„è¯„ä¼°é¡ºåº

1. **å¿«é€Ÿäººå·¥æ¨ç†**ï¼šç®€å•éªŒè¯æ¨¡å‹æ˜¯å¦æ­£å¸¸è¿è¡Œï¼Œç”Ÿæˆçš„æ–‡æœ¬æ˜¯å¦åˆç†ï¼›
2. **è‡ªåŠ¨åŒ–benchmarkè¯„ä¼°**ï¼šå®¢è§‚åœ°è¡¡é‡æ¨¡å‹çš„èƒ½åŠ›ï¼›
3. **ç»“æœå¯¹æ¯”åˆ†æ**ï¼šä¸ä¹‹å‰çš„ç‰ˆæœ¬æˆ–baselineå¯¹æ¯”ï¼Œç¡®è®¤æ¨¡å‹æ€§èƒ½æå‡ã€‚

---

ç»¼ä¸Šæ‰€è¿°ï¼Œæ ¹æ®ä½ çš„éœ€æ±‚ï¼Œæˆ‘å»ºè®®å…ˆç”¨ç¬¬ä¸€ä¸ªæ–¹æ³•ï¼ˆbenchmarkè¯„ä¼°ï¼‰è¿›è¡Œå®¢è§‚è¡¡é‡ï¼Œå†è¿›è¡Œç¬¬äºŒä¸ªï¼ˆäººå·¥æ¨ç†ï¼‰è¿›è¡Œæ„Ÿæ€§éªŒè¯ï¼Œè¿™æ ·ä½ èƒ½å¯¹æ¨¡å‹çš„æ¨ç†èƒ½åŠ›æœ‰ä¸€ä¸ªå…¨é¢çš„ç†è§£ã€‚
