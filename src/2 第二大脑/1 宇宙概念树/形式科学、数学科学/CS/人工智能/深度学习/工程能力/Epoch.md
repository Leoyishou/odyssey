---
comment_id: 3ed157f7
date created: 2025-03-23
date modified: 2025-03-23
draw: null
title: Epoch
---
美音：`[ˈepək]`（类似于“诶帕克”，重音也在第一个音节“诶”）

用通俗的方式讲：

**Epoch（训练轮次）就是把全部训练数据完整地喂给模型“一遍”，叫做一个epoch。**

你可以把它想象成：

> 假设你在学习一本有100道题的数学书，你从头到尾全部做完一遍，就是一个epoch。
> 如果你做了5个epoch，那就意味着你把这本书所有的题目整整做了5遍。

在机器学习中，我们一般不会只看一遍数据就结束，而是反复多次地看（多个epoch）。因为看第一遍可能还没完全掌握，重复几次以后，模型逐渐记住规律并变得更聪明。

**小总结**：

- **1个epoch**：完整地用全部的数据集训练一次
- **多个epoch**：把数据集反复训练多遍，直到模型效果满意为止
