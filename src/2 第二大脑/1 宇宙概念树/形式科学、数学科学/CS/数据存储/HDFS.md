---
date created: 2025-02-24
date modified: 2025-07-10
uid: 5c7e6fc1-0e4b-4ca3-867b-d62c79a62ce6
---
## **HDFS 是啥？**

HDFS（**Hadoop Distributed File System**，Hadoop 分布式文件系统）是 Hadoop 生态中的**核心存储组件**，专门用于**存储超大规模数据（TB/PB 级）**，适用于大数据存储和处理。

---

## **1. HDFS 主要特点**

|特点|解释|通俗理解|
|---|---|---|
|**分布式存储**|数据自动拆分成多个小块，存储在不同机器上|**把 100G 的文件切成 10 份，每份 10G，分别存到 10 台机器上**|
|**高容错性**|每份数据会存多个副本（默认 3 份），防止丢失|**如果 1 台机器坏了，数据还有备份，不影响使用**|
|**适合批处理**|主要用于大规模数据分析，写一次读多次|**适合存海量日志、数据仓库，不适合频繁改数据**|
|**顺序读写**|适合大文件读写，不适合小文件存储|**一次读 100MB、1GB 的大数据很快，但频繁小改动很慢**|

---

## **2. HDFS 和普通文件系统的区别**

|**普通文件系统（如 NTFS, ext4）**|**HDFS**|  
|---|---|---|  
|**适用场景**|个人电脑、服务器本地存储|大数据存储（分布式）|  
|**数据存储**|单机存储|多台机器存储（分布式）|  
|**文件大小**|适合小文件（KB-MB 级）|适合大文件（GB-TB 级）|  
|**数据丢失风险**|硬盘坏了可能丢数据|多副本机制，容错性强|  
|**访问方式**|本地文件系统|通过 Hadoop 访问|

**通俗理解**：

- **普通文件系统（NTFS / ext4）** = 你的 **Windows / Linux 电脑的磁盘**
- **HDFS** = **一个分布式云存储系统**，你把文件上传，它会自动分布到很多台机器上，保证数据安全

---

## **3. HDFS 的核心架构**

HDFS 主要由两个核心组件组成：

- **NameNode（主节点）**：管理元数据（文件目录结构、块分配等）
- **DataNode（数据节点）**：存储真实数据块（Block）

当你上传文件到 HDFS：

1. **文件会被切成多个 128MB（默认大小）的小块**
2. **每个块会被存到多个 DataNode 上（默认 3 份副本）**
3. **NameNode 负责记录这些块存在哪里**
4. **查询数据时，NameNode 指引客户端去正确的 DataNode 读取数据**

### **示例：存储一个 256MB 文件**

- HDFS 会把文件**切成 2 个 128MB 块**
- 每个块会**存 3 份副本**，分布到不同 DataNode 上
- NameNode 记录**这些块存在哪些 DataNode**

📌 **这样即使某台机器坏了，数据还有备份！**

---

## **4. HDFS 适用于哪些场景？**

✅ **适合**

- **大数据存储**（PB 级数据）
- **日志分析**（存储海量网站访问日志）
- **数据仓库**（存储清洗后的数据）
- **离线计算**（如 Spark、Hive 读取 HDFS 数据）

❌ **不适合**

- **存小文件**（HDFS 适合大文件存储，不适合存几 KB 的小文件）
- **低延迟访问**（HDFS 适合批处理，不能像 MySQL 一样秒级响应查询）
- **高频写入更新**（HDFS 不适合 OLTP 业务，不能频繁更新数据）

---

## **5. HDFS 如何和 Hive、Spark 结合使用？**

HDFS 只是一个**存储系统**，它需要配合计算引擎才能发挥作用：| **用途** | **存储（HDFS）** | **计算（SQL / 分析）** | |---|---| | **数据仓库** | HDFS | Hive（SQL 方式查询 HDFS）| | **大数据计算** | HDFS | Spark（并行计算 HDFS 数据）| | **机器学习** | HDFS | Spark ML / TensorFlow |

### **举个例子**

1. **公司收集了 10 亿条用户访问日志**，每天写入 HDFS
2. **Hive 在 HDFS 上创建表**，数据可以用 SQL 查询
3. **Spark 从 HDFS 读取数据**，进行推荐算法计算
4. **计算结果存回 HDFS**，然后提供给前端 API 使用

---

## **6. HDFS 和对象存储（S3、OSS）的对比**

|**特性**|**HDFS**|**对象存储（S3、OSS）**|
|---|---|---|
|**存储类型**|本地分布式存储|云存储|
|**数据访问**|Hadoop 生态系统专用|通用 API（HTTP 访问）|
|**扩展性**|需要 Hadoop 集群|无限扩展|
|**使用成本**|需要运维 Hadoop|按量付费，省运维成本|
|**适用场景**|大数据计算（Spark、Hive）|云计算、大数据存储|

现在很多公司已经**用对象存储（如 AWS S3、阿里 OSS）代替 HDFS**，因为它更容易管理，而且可以直接和 Spark、Presto 结合使用。

---

## **7. 总结**

- **HDFS 是 Hadoop 的分布式存储系统**，专门用于**大数据存储**。
- **数据会被分块存储在多台机器上，并且有多个副本，保证容错**。
- **适合海量数据分析和批处理**（如 Spark、Hive），但**不适合小文件存储和高并发查询**。
- **HDFS 主要用于企业大数据分析**，而**对象存储（S3 / OSS）正在逐渐取代 HDFS**。

---

你做后端开发，如果以后遇到**大数据相关的存储需求**，知道 HDFS 的原理就能帮你选型：

- **小数据、高并发** → MySQL / PostgreSQL / Redis
- **大数据、批处理** → HDFS + Hive / Spark
- **云存储、大规模数据分析** → AWS S3 / 阿里 OSS + Spark

如果你有具体的业务需求，可以继续交流！🚀
