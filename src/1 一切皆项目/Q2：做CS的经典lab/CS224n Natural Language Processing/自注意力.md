---
draw:
title: 自注意力
date created: 2025-02-03
date modified: 2025-02-06
---

要想更形象、深刻地理解 Transformer，可以先从它的核心思想和整体结构入手，然后再去体会它为什么要用这种结构、它是如何将之前的 RNN/CNN 等结构加以改进的。下面提供一些帮助理解的思路和类比，供你参考：

  

一、核心思想：自注意力（Self-Attention）

Transformer 最突出的创新点就是基于自注意力机制（Self-Attention），它可以让网络在处理序列时，根据内容本身来决定"谁应该更加关注谁"。

你可以把自注意力想象成一个"**同学互相评分**"的场景：在一段文本中，每个"词"就像一位同学，每位同学需要给班里其他同学打分，打分越高表示自己越应该关注那位同学的信息。最后每位同学会结合别人的信息来丰富自己。

- 每个词会计算对所有词的注意力权重，并将这些权重加权地融合进来。
- 注意力权重越大，就表示这个词在当前词的理解里越重要。
- 对比 RNN/CNN：
	- 传统 RNN 是一种顺序阅读文本的方式，当前时刻会依赖前面时刻的隐藏状态，不能很好地捕捉远距离依赖。
	- CNN 也要通过卷积核在局部滑动并多次叠加卷积层，才能逐渐把远距离信息捕捉起来。
- Transformer 直接通过自注意力机制，让每个位置"一次就能看到"序列中所有其他位置的信息（可以并行处理），从而让捕捉全局依赖关系变得高效灵活。

  

二、整体结构：编码器-解码器（Encoder-Decoder）框架

  

最初的 Transformer（如论文《Attention is All You Need》）是为了机器翻译而设计的，使用了Encoder-Decoder的结构。但在很多下游任务中，我们也常常只用 Encoder（例如 BERT）或只用 Decoder（例如 GPT）部分。

- Encoder：把输入序列编码成一个更高级的表示，即把输入序列中的各个位置（词）"翻译"成更能被模型理解的向量。
- Decoder：基于 Encoder 的输出和部分目标序列信息，逐步生成目标序列（翻译、文本生成等）。

  

Encoder 内部的结构：

1. 输入嵌入 + 位置编码：
	- 把每个词或 token 映射到一个向量（Embedding），这是你常见的 " ->[向量]" 的操作。
	- 因为自注意力不再显式依赖 "顺序结构"，所以还要加入"位置编码" 来告诉模型输入序列中每个词的相对或绝对位置。

2. 自注意力层（Multi-Head Self-Attention）：
	- 每个词对整个序列进行"打分"，从而获取上下文信息。
	- 这里的 "Multi-Head" 表示模型会并行使用多个注意力头，每个注意力头都可以"关注"文本里的不同方面（比如某些头专注于语法关系，另一些头专注于语义关联），然后将它们的结果拼接或加和在一起，形成更丰富的表示。

3. 前向反馈网络（Feed-Forward Network, FFN）：
	- 在每个注意力层后面，还会有一个简单的多层感知机（MLP），对每个位置的向量单独地进行非线性变换。这就像是 "对每个词做进一步处理"。

4. 残差连接 + Layer Norm：
	- 跳跃连接（residual）用来缓解深层网络训练困难；Layer Normalization 用来稳定和加快训练收敛。

  

Decoder 内部的结构：

Decoder 的每个层也包含自注意力机制，但分成两个部分：

1. Masked Self-Attention：保证解码时只能看到已生成的部分，防止"剧透"；
2. Encoder-Decoder Attention：向 Encoder 的输出"查询"信息，以便生成当前词时可以参考原文或条件信息；
3. 前向反馈网络：同样用于对解码中的向量做进一步的特征变换。

  

三、分步骤的形象理解

可以把 Transformer 分解为几个"动作"来理解：

1. 输入词向量化：
	- 每个词先变成一个向量，你可以把它理解成描述这个词"语义特征"的一个数字向量。再加上位置编码，让模型知道这是第 1 个词、还是第 2 个词、还是第 10 个词。

2. 自注意力：谁该关注谁？
	- 对于序列中的每个词，生成三个向量：
	- Query（查询），Key（键），Value（值）。
	- 用 Query 和 Key 计算相似度（点积），相似度越大说明词 A 更应该关注词 B。
	- 将相似度（再经过 Softmax）当成加权系数，去对 Value 做加权求和，得到融合了全局信息的新表示。
	- 多个注意力头（Multi-Head）同时进行，这样每个头就像"不同的观察角度"，最后把它们的输出综合起来。

3. 前向网络：深挖信息
	- 把注意力层输出的结果，再经过一个全连接/非线性的网络，就像对每个词的位置做"进一步处理"，萃取更抽象的特征。

4. 层与层之间的残差和归一化
	- 保持上下文梯度流动通畅，避免训练中梯度消失或爆炸，提升稳定性。

5. 不断堆叠：
	- 将若干个这种 "自注意力 + 前向网络 + 残差 + 归一化" 的模块堆叠，就构成了编码器或解码器的大部分主体。

6. （如果是 Decoder）再和 Encoder 交互
	- Decoder 里面专门有一个"Encoder-Decoder Attention"，把 Encoder 的输出当做 Key/Value，把 Decoder 当前层的中间表示当做 Query，让生成端能参考输入信息。

  

四、结合数学公式与直觉

你提到已经理解 MLP 里的  并接激活函数来拟合，这里 Transformer 的 Feed Forward 部分和常规的 MLP 很相似。而它的神来之笔在于自注意力：

1. 自注意力的公式（以单头为例）：

  

其中：

- 是输入序列的向量表示；是可学习的参数矩阵；
- 是缩放因子，防止分母过小或过大导致梯度不稳定；
- 让所有的注意力权重加和为 1。

1. Multi-Head：

把上面这套操作同时做 8 次或更多次，然后再把这些结果拼接起来，通过一个线性变换。这样可以保留多方面的注意力信息。

  

从直觉上来讲，可以理解为"每个位置"在做信息整合之前，先用不同的方式去"看别的位置"、"决定关注度"，然后再把不同视角下的关注结果都合并起来。

  

五、为什么这样做有效？

- 并行性：自注意力让整个序列的处理可以在一个层级并行进行，而不像 RNN 那样顺序依赖，从而极大加快了训练速度和效率。
- 全局关联：每个位置随时都能查看到其他位置的信息，远距离依赖也能够被轻松捕捉。
- 多头机制：让模型可以在不同子空间中学习到不同类型的特征或依赖模式，呈现出比单一注意力头更强的表达能力。

  

六、在脑海里建模 Transformer

  

如果想让这个概念更形象，可以尝试以下几种想象方式：

1. "讨论组"比喻：

- 序列中的每个词是一位组员，每个人都有自己携带的信息（Value），也都有自己能发问（Query）和被询问（Key）的方式。
- 当"讨论"开始时，每个人先根据自己的问题（Query）去看所有其他人的特征（Key），算出相似度来决定"要听谁说话"。
- 最后通过这种"注意力加权"把他人带来的信息"听"进自己这里，更新自己的状态。

1. "看世界"比喻：

- 每个注意力头都像一副特殊的眼镜，它能捕捉到句子/序列中的某些关系（比如语法结构或核心语义）。每个词都会戴上这些眼镜，看看整句话谁最重要，然后加权吸收信息。多头注意力就像戴上了很多副不同风格的眼镜。

1. "全局扫描"对比 "局部扫描"：

- RNN/CNN 更多是"一步步或者局部"去提取信息；
- Transformer 在一个层就可以做"一次全局扫描"。想象你手里有一束光，可以一次就照在所有词上，然后根据他们与当前词之间的重要程度来融合信息。

  

七、学习建议

- 循序渐进地实现小示例：

可以先尝试用一个非常小的 Transformer，甚至手写一个 Self-Attention 层，来看看计算过程。

- 可视化工具：

有一些可视化 Demo（比如 The Illustrated Transformer），能让你直观地看到注意力分布。

- 调试与观察：

在调试过程里打印出注意力矩阵，看看模型到底"关注"了哪些位置。

- 常见的改进版：

比如 BERT、GPT、T5 以及它们的各种变体，都在 Transformer 的基础上进行一些改动或针对性增强，理解它们也有助于更好地加深对 Transformer 原理的感受。

  

总结

  

要形象深刻地理解 Transformer，最关键的是抓住"自注意力机制"这条主线，然后再结合多头注意力 + 前向网络 + 残差连接这几个重要模块去形成完整的心智模型。自注意力让每个位置都能够"看到"整个序列，并且在不同的头中以不同方式关注别的词，从而一次就能得到全局的关联信息。

  

希望这些类比和思路能让你在脑中更轻松地描绘出 Transformer 的工作过程。如果能配合简单的实现、可视化注意力权重、再结合一些小任务来实验，理解会更加深刻。祝学习顺利！
