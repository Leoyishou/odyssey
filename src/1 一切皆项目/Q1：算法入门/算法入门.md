---
draw:
tags: []
title: 算法入门
date created: 2025-01-29
date modified: 2025-01-29
---

> 我也是大一进组，只不过在大一上学期先学习了mit1806，6041，6042j，6006，然后也开始做 DL，学了Stanford CS229 CS230 CS231n CS224n CS131。
>
> 看这些课收获特别大，做作业的时候收获更大，至今很多想法仍然来自于当时看课时的知识。
> 比如说我前几天去推在对抗攻击中怎么混合xxx最好，里面用了很多算子反向传播*时的解析解，而这些都是CS231n assignment2里的。再比如说之前做adversarial patch，能联想到deepdream*上去，然后用deepdream的一些解释来解释adversarial texture为什么在情况A和情况B下差别很大。总之这些资源真的对我帮助非常非常大。
>
> 看完这些课，并认真做完作业，我觉得就可以去选个方向follow论文，去进组。
> 只不过我一开始搞无监督学习，结果对我这种没资源的人来说是个大坑，啥都做不动。。后来转多模态，表征学习，对抗攻击，这些方向也越来越符合我的兴趣。我的兴趣可能比较奇特，就是喜欢对同一个问题从不同角度来解释，尤其是那些解释互相矛盾的时候，一下子就兴奋起来了。。就比如说diffusion，你既可以从ELBO推*，也可以从SDE推。为什么robustnesst和accuracy存在tradeoff，也可以从nonrobust feature的角度考虑，也可以rethinking一下robustness metric等等。
>
> 回归正题，我觉得AI最好的办法就是看这些课，写这些作业（尤其是作业）。这是我见过的最好的资源。我觉得直接去看论文，真的有些离谱，是特别低效的办法。看完这些课，再去选领域follow论文，我觉得不论是从知识的广度来说，还是深度来说，都是最优选择。

下面是一份基于原文核心内容的**要点提炼**，方便你快速了解作为算法/机器学习工程师在面试和日常工作中需要重点关注的领域。主要围绕文中提到的**三大能力**展开：**理论基本功、工程能力、业务理解能力**，并附上文中一些典型问题示例和工具建议。

---

## 一、理论基本功

1. **传统机器学习算法原理**
    
    - 经典三板斧：LR、SVM、GBDT 的原理及内部细节（正则化、损失函数、为什么好/不好等）。
    - 常用库的理解：比如 xgboost 的改进点、优势，以及与其它集成模型的对比。
    - 特征工程相关：如何做特征选择、特征构造，为什么这样做。
2. **深度学习基础**
    
    - **常见网络结构**：CNN、RNN、LSTM、GRU 等核心原理、使用场景及优缺点。
    - **梯度问题**：梯度消失/爆炸的原因和常见的解决方案（比如梯度裁剪、残差网络、正则化等）。
    - **激活函数**：ReLU、Sigmoid、Tanh 等的优缺点；为什么在实际训练中常用 ReLU。
    - **正则化**：L1 和 L2 正则化的区别与联系，为什么有助于防止过拟合。
3. **数学与统计基础**
    
    - 概率统计、线性代数、微积分等在机器学习中的应用。
    - 《统计学习方法》（李航）的相关内容：决策理论、生成模型与判别模型、EM 算法等。

> **提示**：扎实的理论基础能够帮助你在遇到新算法或前沿算法时更快上手并理解本质。

---

## 二、工程能力

1. **模型落地与部署**
    
    - **如何把模型部署到线上**：推理速度、资源占用、吞吐量等都要考量。
    - **模型压缩、剪枝、量化**：尤其是深度学习模型过大的时候，如何减小模型体积并加速推理，量化为 INT8、BF16 等格式的方法。
2. **性能优化与加速**
    
    - **数据预处理的速度**：大量训练数据的读取、清洗、转换往往是瓶颈。
    - **推理速度优化**：通过硬件指令集（如 AVX-512）或高性能计算库（oneDNN、OpenVINO、DAAL 等）实现推理提速。
    - **XGBoost 加速**：在 CPU 上如何使用 Intel 优化版 XGBoost，以及 Intel DAAL 库对数据分析/训练的加速。
3. **通用工程素养**
    
    - **编程能力**：算法岗同样需要考察代码风格、数据结构与算法题（LeetCode 类型）、系统设计等。
    - **版本管理、代码规范、自动化测试** 等通用软件工程的必备知识。

> **提示**：在实际工作中，工程实现与项目落地比"只会调包"复杂得多。对工程环节足够敏感并能提出或实现加速方案，往往是面试官非常看重的能力。

---

## 三、业务理解能力

1. **业务场景题**
    
    - 蔬菜价格预测：如何构造特征？为什么要这样做？
    - 用户画像预测：浏览数据判断用户是否有车，如何结合多种信息？
    - 如何构建可靠的评测集：指标设计、样本分布、线上线下的一致性等。
2. **理解业务需求，输出可行方案**
    
    - 为什么选择某种算法或模型？与业务目标（准确率、召回率、用户体验、实时性等）如何匹配？
    - 在"精度"与"速度"、"模型复杂度"与"易用性"之间做取舍，需要站在业务角度思考。
3. **整体流程的设计思维**
    
    - 面试官希望看到的是：能否从业务问题→数据处理→算法方案→指标评估→线上部署→持续迭代 全流程考虑。

> **提示**：很多情况下"会建模"只是前提，更重要的是能否结合实际场景与数据特点，提出可落地并有价值的解决方案。

---

## 四、常见的面试问题示例（文中提及）

- **深度学习相关**
    
    1. RNN、LSTM、GRU 的特点和区别。
    2. 梯度弥散/爆炸的成因和对应的解决方案。
    3. 常见激活函数（ReLU、Sigmoid、Tanh）的优缺点及应用场景。
    4. 为什么 L2 正则化能防止过拟合？L1 和 L2 的区别。
- **传统 ML 模型原理**
    
    1. LR、SVM、GBDT 的基本原理，损失函数、正则化项如何设计。
    2. xgboost 的改进点，以及它相比其他 GBDT 实现好在哪里。
    3. 特征工程：如何做特征组合、特征筛选、特征重要度评估。
- **工程/性能优化**
    
    1. 若模型太大、推理速度太慢，如何进行压缩、量化、剪枝？
    2. 线上模型如何部署以达到实时或准实时要求？
    3. 数据预处理成为瓶颈后如何提升效率？
    4. 使用英特尔 oneDNN、OpenVINO、DAAL 等工具如何提速？
- **业务场景题**
    
    1. 给你一个预测蔬菜价格的项目，如何选取和构造特征？
    2. 给定某个用户的浏览记录，如何判断此人是否有车？
    3. 如何设计一个稳定、能真实反映模型效果的评测集？

---

## 五、文中提到的工具和优化思路

- **Intel oneAPI 生态**
    
    - **oneDNN**：深度学习的底层优化库，针对 CPU 的各种指令集做了优化。
    - **OpenVINO**：对模型进行量化、压缩、加速推理；也包含对 OpenCV 的性能优化。
    - **DAAL**：主要面向传统机器学习和数据分析的加速（如加速 XGBoost）。
- **模型量化与指令集**
    
    - **AVX-512**：CPU 的矢量化指令，可提升矩阵运算和卷积操作的吞吐量。
    - **BF16 / INT8**：低精度运算在保留较高精度的同时，大幅提升训练和推理速度。

---

## 如何结合文章内容提升自己

1. **理论基础**：补齐统计学习方法、深度学习核心结构和数学的短板；重视《李航-统计学习方法》或斯坦福经典课程（CS229/CS231/CS224）的理论部分。
2. **工程实践**：
    - 多做项目：哪怕是小型项目也要完整跑通数据清洗、模型训练、部署、优化全流程；
    - 学会使用性能分析工具，了解如何做大规模分布式训练/推理、如何做量化/裁剪/部署。
3. **业务场景**：
    - 多问"为什么"：为什么要这样建模？为什么选择这种特征？为什么选择这个评价指标？
    - 尝试把自己的项目包装成一个完整的业务案例，从需求到上线都能说清楚。

---

### 结语

想从事算法/机器学习方向，需要在**算法理论、代码实现、业务理解**上都至少"达标"，然后再根据具体岗位和公司要求进行专项加强。文中提到的各种问题和工具（OpenVINO、oneDNN、DAAL 等）是典型的"工程落地"型面试热点，一定要结合自己的项目经验去理解和掌握。只会调包/炼丹可能无法支撑你走得很远，建议在工程与业务层面多下功夫。祝你求职和学习顺利！
