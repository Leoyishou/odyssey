import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,f as r,o as i}from"./app-DokaGNO4.js";const l={};function a(s,t){return i(),o("div",null,t[0]||(t[0]=[r("<ul><li>目的: 规定爬虫可以访问网站的哪些部分,以及如何访问。</li><li>实现: 通常通过在网站根目录下放置一个名为 &quot;robots.txt&quot; 的文本文件来实现。</li><li>主要指令: <ul><li>Allow: 允许访问的目录或文件</li><li>Disallow: 禁止访问的目录或文件</li><li>Sitemap: 指定网站地图的位置</li><li>User-agent: 指定适用的爬虫</li></ul></li><li>非强制性:robots 协议是一种<strong>君子协定</strong>,爬虫可以选择遵守或忽略。</li></ul>",1)]))}const p=e(l,[["render",a],["__file","robots 协议.html.vue"]]),c=JSON.parse('{"path":"/2%20%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/1%20%E8%8A%82%E7%82%B9/CS/%E7%BD%91%E7%BB%9C/robots%20%E5%8D%8F%E8%AE%AE.html","title":"robots 协议","lang":"zh-CN","frontmatter":{"draw":null,"tags":[],"title":"robots 协议","date created":"2024-07-04T00:00:00.000Z","date modified":"2024-11-12T00:00:00.000Z","description":"目的: 规定爬虫可以访问网站的哪些部分,以及如何访问。 实现: 通常通过在网站根目录下放置一个名为 \\"robots.txt\\" 的文本文件来实现。 主要指令: Allow: 允许访问的目录或文件 Disallow: 禁止访问的目录或文件 Sitemap: 指定网站地图的位置 User-agent: 指定适用的爬虫 非强制性:robots 协议是一种君子协...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/2%20%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/1%20%E8%8A%82%E7%82%B9/CS/%E7%BD%91%E7%BB%9C/robots%20%E5%8D%8F%E8%AE%AE.html"}],["meta",{"property":"og:site_name","content":"转了码的刘公子"}],["meta",{"property":"og:title","content":"robots 协议"}],["meta",{"property":"og:description","content":"目的: 规定爬虫可以访问网站的哪些部分,以及如何访问。 实现: 通常通过在网站根目录下放置一个名为 \\"robots.txt\\" 的文本文件来实现。 主要指令: Allow: 允许访问的目录或文件 Disallow: 禁止访问的目录或文件 Sitemap: 指定网站地图的位置 User-agent: 指定适用的爬虫 非强制性:robots 协议是一种君子协..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-11-24T16:17:22.000Z"}],["meta",{"property":"article:modified_time","content":"2024-11-24T16:17:22.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"robots 协议\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2024-11-24T16:17:22.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"转了码的刘公子\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[],"git":{"createdTime":1732465042000,"updatedTime":1732465042000,"contributors":[{"name":"Luis","email":"liuysh20@gmail.com","commits":1}]},"readingTime":{"minutes":0.46,"words":137},"filePathRelative":"2 第二大脑/1 节点/CS/网络/robots 协议.md","localizedDate":"2024年11月25日","autoDesc":true}');export{p as comp,c as data};
