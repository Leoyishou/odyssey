import{_ as d}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as o,f as s,a as t,b as n,d as e,e as r,r as a,o as u}from"./app-DokaGNO4.js";const p={};function g(A,l){const i=a("RouteLink");return u(),o("div",null,[l[49]||(l[49]=s('<p>以下是对这些 LLM（大型语言模型）相关参数和选项的解释与介绍：</p><ol><li><p><strong>Model（模型）</strong>：<br> 指定所使用的语言模型版本或类型。不同的模型在训练数据、参数规模、性能和特点方面可能有所差异。选择不同模型可以影响回答的质量、语气和速度。</p></li><li><p><strong>Token count（令牌计数）</strong>：<br> 令牌（Token）是模型处理文本的基本单位，一般由词语、子词或字符片段组成。<strong>Token count</strong> 通常指已经输入或产生的文本长度，模型对令牌的数量有一定限制。较大的令牌上限允许模型产生更长的输出文本，但处理时间和费用也会提高。</p></li><li><p><strong>Temperature（温度）</strong>：<br> 温度是一个用于控制模型回答的“随机性”或“创造性”的参数。</p><ul><li>当温度接近 0 时，模型更倾向于选择概率最高的词语，回答会相对保守、确定性较高且重复率可能较高。</li><li>当温度较高时，模型回答会更具多样性和创意，可能更有“发散思维”，但同时不确定性也增加，回答可能显得更不稳定。</li></ul></li><li><p><strong>Tools（工具） / Structured output（结构化输出） / Code execution（代码执行） / Function calling（函数调用）</strong>：<br> 这些选项主要用于增强 LLM 的功能和输出格式。</p><ul><li><strong>Structured output</strong>：可用来指定输出的格式或结构（例如 JSON 格式、列表等），方便后续处理。</li><li><strong>Code execution（代码执行）</strong>：在有些环境中，模型可能集成了执行特定代码片段的能力，可根据用户指令进行运算或调用外部 API。</li><li><strong>Function calling（函数调用）</strong>：允许模型以受控的方式调用已定义的函数，从而实现更好的工具使用能力，比如调用计算器函数、数据库查询函数等，让回答更具实用性和可控性。</li></ul></li><li><p><strong>Advanced settings（高级设置） / Safety settings（安全设置）</strong>：</p><ul><li><strong>Safety settings</strong>：用于控制模型回答中的内容安全，例如过滤敏感信息、不适宜内容。可根据策略调整这些设置以确保回答符合道德规范和平台政策。</li></ul></li><li><p><strong>Add stop sequence（添加停止序列）</strong>：<br> 停止序列是一段特殊的文本（如某些标记符号），在生成文本时，如果模型输出该序列，就会停止继续生成。这有助于控制回答的长度或防止无穷延续。</p></li><li><p><strong>Output length（输出长度）</strong>：<br> 指定模型回答的最大长度（以令牌计）。如果设定此值，模型在达到该限制时将停止生成更多文本。较大的输出长度允许更详细的回答，但可能增加冗余。</p></li><li><p><strong>Top P（核采样）</strong>：<br> 与 Temperature 类似，Top P（又称 nucleus sampling）控制采样的随机性方式不同。</p><ul><li>模型会从概率分布中选取一组累计概率达到 P 的词语作为候选，然后从这些候选中随机选择下一个词。当 P 接近 1 时，模型有更多候选可选，因此回答更具发散性。较低的 P 值则让模型只从最有可能的一小部分词中进行选择，回答更加保守和可控。</li></ul></li></ol><p>通过调节上述参数，可以在回答的准确度、创造性、长度、格式、安全性等多个维度对模型的输出进行微调和优化。</p><h2 id="openai" tabindex="-1"><a class="header-anchor" href="#openai"><span>OpenAI</span></a></h2><p><a href="https://platform.openai.com/docs/assistants/how-it-works" target="_blank" rel="noopener noreferrer">How Assistants work - OpenAI API</a></p>',5)),t("table",null,[l[48]||(l[48]=t("thead",null,[t("tr",null,[t("th",null,"主分类"),t("th",null,"子项目"),t("th")])],-1)),t("tbody",null,[l[7]||(l[7]=t("tr",null,[t("td",null,"Get started"),t("td",null,"Overview"),t("td")],-1)),l[8]||(l[8]=t("tr",null,[t("td"),t("td",null,"Quickstart"),t("td")],-1)),l[9]||(l[9]=t("tr",null,[t("td"),t("td",null,"Models"),t("td")],-1)),l[10]||(l[10]=t("tr",null,[t("td"),t("td",null,"Changelog"),t("td")],-1)),l[11]||(l[11]=t("tr",null,[t("td"),t("td",null,"Terms and policies"),t("td")],-1)),l[12]||(l[12]=t("tr",null,[t("td",null,"Capabilities"),t("td",null,"Text generation"),t("td")],-1)),l[13]||(l[13]=t("tr",null,[t("td"),t("td",null,"Image generation"),t("td")],-1)),l[14]||(l[14]=t("tr",null,[t("td"),t("td",null,"Vision"),t("td")],-1)),l[15]||(l[15]=t("tr",null,[t("td"),t("td",null,"Audio generation"),t("td")],-1)),l[16]||(l[16]=t("tr",null,[t("td"),t("td",null,"Text to speech"),t("td")],-1)),l[17]||(l[17]=t("tr",null,[t("td"),t("td",null,"Speech to text"),t("td")],-1)),l[18]||(l[18]=t("tr",null,[t("td"),t("td",null,"Vector embeddings"),t("td")],-1)),l[19]||(l[19]=t("tr",null,[t("td"),t("td",null,"Moderation"),t("td")],-1)),l[20]||(l[20]=t("tr",null,[t("td"),t("td",null,"Reasoning"),t("td")],-1)),l[21]||(l[21]=t("tr",null,[t("td",null,"Guides"),t("td",null,"Function calling"),t("td",null,"让 AI 生成入参调本地函数")],-1)),t("tr",null,[l[2]||(l[2]=t("td",null,null,-1)),l[3]||(l[3]=t("td",null,"Structured outputs",-1)),t("td",null,[l[1]||(l[1]=n("借助 ")),e(i,{to:"/2%20%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/1%20%E8%8A%82%E7%82%B9/CS/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/AIGC/API/Pydantic.html"},{default:r(()=>l[0]||(l[0]=[n("Pydantic")])),_:1})])]),l[22]||(l[22]=t("tr",null,[t("td"),t("td",null,"Evaluations"),t("td")],-1)),l[23]||(l[23]=t("tr",null,[t("td"),t("td",null,"Fine-tuning"),t("td",null,"使用您的数据将模型适应您的特定用例")],-1)),l[24]||(l[24]=t("tr",null,[t("td"),t("td",null,"Distillation"),t("td",null,"使用生产日志评估和微调模型")],-1)),l[25]||(l[25]=t("tr",null,[t("td"),t("td",null,"Realtime API"),t("td",null,"原生语音转语音而不是TTS")],-1)),l[26]||(l[26]=t("tr",null,[t("td"),t("td",null,"Batch API"),t("td",null,"批处理，适合那种一两个小时内不需要结果的任务，放在 openai 那里慢慢做，收费比正常接口低")],-1)),l[27]||(l[27]=t("tr",null,[t("td",null,"Assistants"),t("td",null,"Overview"),t("td",null,[n("助手可以并行访问"),t("strong",null,"多种工具"),n("。这些可以是 OpenAI 托管的工具——像"),t("a",{href:"https://platform.openai.com/docs/assistants/tools/code-interpreter",target:"_blank",rel:"noopener noreferrer"},"代码解释器"),n("和"),t("a",{href:"https://platform.openai.com/docs/assistants/tools/file-search",target:"_blank",rel:"noopener noreferrer"},"文件搜索"),n(" ——或者您构建/托管的工具(通过"),t("a",{href:"https://platform.openai.com/docs/assistants/tools/function-calling",target:"_blank",rel:"noopener noreferrer"},"函数调用"),n(")。相当于是 OpenAI 的函数+本地函数，其实就是我之前做的 viva")])],-1)),l[28]||(l[28]=t("tr",null,[t("td"),t("td",null,"Quickstart"),t("td")],-1)),l[29]||(l[29]=t("tr",null,[t("td"),t("td",null,"Deep dive"),t("td")],-1)),l[30]||(l[30]=t("tr",null,[t("td"),t("td",null,"Tools"),t("td")],-1)),l[31]||(l[31]=t("tr",null,[t("td"),t("td",null,"What's new?"),t("td")],-1)),l[32]||(l[32]=t("tr",null,[t("td"),t("td",null,"Migration guide"),t("td")],-1)),l[33]||(l[33]=t("tr",null,[t("td",null,"ChatGPT"),t("td",null,"Actions"),t("td")],-1)),l[34]||(l[34]=t("tr",null,[t("td"),t("td",null,"Release notes"),t("td")],-1)),t("tr",null,[l[5]||(l[5]=t("td",null,"Best practices",-1)),t("td",null,[e(i,{to:"/2%20%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/1%20%E8%8A%82%E7%82%B9/CS/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/AIGC/API/Prompt.html"},{default:r(()=>l[4]||(l[4]=[n("Prompt")])),_:1})]),l[6]||(l[6]=t("td",null,null,-1))]),l[35]||(l[35]=t("tr",null,[t("td"),t("td",null,"Production best practices"),t("td")],-1)),l[36]||(l[36]=t("tr",null,[t("td"),t("td",null,"Safety best practices"),t("td")],-1)),l[37]||(l[37]=t("tr",null,[t("td"),t("td",null,"Prompt caching"),t("td",null,"Openai 侧的缓存，降低成本")],-1)),l[38]||(l[38]=t("tr",null,[t("td"),t("td",null,"Model selection"),t("td")],-1)),l[39]||(l[39]=t("tr",null,[t("td"),t("td",null,"Latency optimization"),t("td")],-1)),l[40]||(l[40]=t("tr",null,[t("td"),t("td",null,"Accuracy optimization"),t("td")],-1)),l[41]||(l[41]=t("tr",null,[t("td"),t("td",null,"Advanced usage"),t("td")],-1)),l[42]||(l[42]=t("tr",null,[t("td",null,"Resources"),t("td",null,"Libraries"),t("td")],-1)),l[43]||(l[43]=t("tr",null,[t("td"),t("td",null,"Prompt examples"),t("td")],-1)),l[44]||(l[44]=t("tr",null,[t("td"),t("td",null,"Rate limits"),t("td")],-1)),l[45]||(l[45]=t("tr",null,[t("td"),t("td",null,"Prompt generation"),t("td")],-1)),l[46]||(l[46]=t("tr",null,[t("td"),t("td",null,"Error codes"),t("td")],-1)),l[47]||(l[47]=t("tr",null,[t("td"),t("td",null,"Deprecations"),t("td")],-1))])]),l[50]||(l[50]=s(`<h3 id="限流" tabindex="-1"><a class="header-anchor" href="#限流"><span>限流</span></a></h3><figure><img src="https://imagehosting4picgo.oss-cn-beijing.aliyuncs.com/imagehosting/fix-dir%2Fpicgo%2Fpicgo-clipboard-images%2F2024%2F10%2F27%2F04-27-30-a4b9a2b46b404be9adbfdd83d2876a2f-202410270427685-ad1693.png" alt="image.png|1000" tabindex="0" loading="lazy"><figcaption>image.png|1000</figcaption></figure><h3 id="结果约束" tabindex="-1"><a class="header-anchor" href="#结果约束"><span>结果约束</span></a></h3><p>JSON mode和Structured Outputs的主要区别在于：</p><ol><li>JSON mode（基础版）:</li></ol><ul><li>只确保输出是有效的JSON格式</li><li>不保证输出符合任何特定的数据结构</li><li>没有数据验证和类型检查</li><li>你需要自己处理数据验证和错误情况</li></ul><ol><li>Structured Outputs（进阶版）:</li></ol><ul><li>不仅确保输出是有效的JSON格式</li><li>还能确保输出严格匹配你指定的schema（数据结构）</li><li>提供了完整的数据验证功能</li><li>支持复杂的数据类型定义和嵌套结构</li><li>自动进行类型检查和验证</li></ul><p>举个例子来说： 假设你想要获取一个用户的信息：</p><p>使用JSON mode时，模型可能返回：</p><div class="language-json line-numbers-mode" data-highlighter="shiki" data-ext="json" data-title="json" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">{</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">  &quot;name&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;张三&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">  &quot;age&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;25岁&quot;</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  // 注意这里age是字符串</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>而使用Structured Outputs时，如果你定义了schema要求age必须是数字类型：</p><div class="language-json line-numbers-mode" data-highlighter="shiki" data-ext="json" data-title="json" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">{</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">  &quot;name&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;张三&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">  &quot;age&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">25</span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">  // 这里一定是数字类型</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>所以Structured Outputs提供了更严格的数据控制，让你的应用程序能够更可靠地处理模型输出。这也是为什么在可能的情况下，建议使用Structured Outputs而不是基础的JSON mode。</p><h2 id="anthropic" tabindex="-1"><a class="header-anchor" href="#anthropic"><span>Anthropic</span></a></h2><p><strong>project knowledge</strong> 还没有提供 API</p>`,16))])}const h=d(p,[["render",g],["__file","AI API.html.vue"]]),b=JSON.parse('{"path":"/2%20%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/1%20%E8%8A%82%E7%82%B9/CS/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/AIGC/API/AI%20API.html","title":"","lang":"zh-CN","frontmatter":{"description":"以下是对这些 LLM（大型语言模型）相关参数和选项的解释与介绍： Model（模型）： 指定所使用的语言模型版本或类型。不同的模型在训练数据、参数规模、性能和特点方面可能有所差异。选择不同模型可以影响回答的质量、语气和速度。 Token count（令牌计数）： 令牌（Token）是模型处理文本的基本单位，一般由词语、子词或字符片段组成。Token c...","head":[["meta",{"property":"og:url","content":"https://vuepress-theme-hope-docs-demo.netlify.app/2%20%E7%AC%AC%E4%BA%8C%E5%A4%A7%E8%84%91/1%20%E8%8A%82%E7%82%B9/CS/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/AIGC/API/AI%20API.html"}],["meta",{"property":"og:site_name","content":"转了码的刘公子"}],["meta",{"property":"og:description","content":"以下是对这些 LLM（大型语言模型）相关参数和选项的解释与介绍： Model（模型）： 指定所使用的语言模型版本或类型。不同的模型在训练数据、参数规模、性能和特点方面可能有所差异。选择不同模型可以影响回答的质量、语气和速度。 Token count（令牌计数）： 令牌（Token）是模型处理文本的基本单位，一般由词语、子词或字符片段组成。Token c..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:image","content":"https://imagehosting4picgo.oss-cn-beijing.aliyuncs.com/imagehosting/fix-dir%2Fpicgo%2Fpicgo-clipboard-images%2F2024%2F10%2F27%2F04-27-30-a4b9a2b46b404be9adbfdd83d2876a2f-202410270427685-ad1693.png"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2024-12-11T14:48:27.000Z"}],["meta",{"property":"article:modified_time","content":"2024-12-11T14:48:27.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"\\",\\"image\\":[\\"https://imagehosting4picgo.oss-cn-beijing.aliyuncs.com/imagehosting/fix-dir%2Fpicgo%2Fpicgo-clipboard-images%2F2024%2F10%2F27%2F04-27-30-a4b9a2b46b404be9adbfdd83d2876a2f-202410270427685-ad1693.png\\"],\\"dateModified\\":\\"2024-12-11T14:48:27.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"转了码的刘公子\\",\\"url\\":\\"https://mister-hope.com\\"}]}"]]},"headers":[{"level":2,"title":"OpenAI","slug":"openai","link":"#openai","children":[{"level":3,"title":"限流","slug":"限流","link":"#限流","children":[]},{"level":3,"title":"结果约束","slug":"结果约束","link":"#结果约束","children":[]}]},{"level":2,"title":"Anthropic","slug":"anthropic","link":"#anthropic","children":[]}],"git":{"createdTime":1732465042000,"updatedTime":1733928507000,"contributors":[{"name":"Luis","email":"liuysh20@gmail.com","commits":2}]},"readingTime":{"minutes":4.99,"words":1496},"filePathRelative":"2 第二大脑/1 节点/CS/人工智能/AIGC/API/AI API.md","localizedDate":"2024年11月25日","autoDesc":true}');export{h as comp,b as data};
